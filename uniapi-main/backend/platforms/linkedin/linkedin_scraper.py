"""
LinkedIn Scraper - é¢†è‹±çˆ¬è™«
ä½¿ç”¨Playwrightæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®LinkedIn
å¢å¼ºäººç±»è¡Œä¸ºæ¨¡æ‹Ÿï¼šéšæœºå»¶è¿Ÿã€é¼ æ ‡ç§»åŠ¨ã€æ»šåŠ¨
"""

import json
import time
import random
import logging
from typing import List, Dict, Optional
from playwright.sync_api import sync_playwright, Page, Browser
from src.platform_scraper_base import PlatformScraperBase

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class LinkedInScraper(PlatformScraperBase):
    """LinkedInå¹³å°scraper"""

    def __init__(self, auth_file: str = "linkedin_auth.json"):
        """
        åˆå§‹åŒ–LinkedIn scraper

        Args:
            auth_file: è®¤è¯é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆstorage_state JSONï¼‰
        """
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æ–°çš„storage_stateæ ¼å¼
        import os
        self.use_storage_state = os.path.exists(auth_file) and auth_file.endswith('linkedin_auth.json')

        if self.use_storage_state:
            # ä½¿ç”¨storage_stateï¼ˆæ¨èï¼‰
            self.storage_state_file = auth_file
            logger.info(f"Using storage_state from {auth_file}")

            # åˆå§‹åŒ–base class
            super().__init__({}, 'LinkedIn')

        else:
            # å°è¯•æ—§çš„platforms_auth.jsonæ ¼å¼
            with open(auth_file, 'r') as f:
                config = json.load(f)

            super().__init__(config.get('linkedin', {}), 'LinkedIn')

            self.cookies = self.auth_config.get('cookies', {})
            self.headers = self.auth_config.get('headers', {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            })
            self.storage_state_file = None

        # Playwright browser
        self.playwright = None
        self.browser = None
        self.page = None

    def _human_like_delay(self, min_seconds: float = 1.0, max_seconds: float = 3.0):
        """æ·»åŠ éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸º - ä½¿ç”¨éå‡åŒ€åˆ†å¸ƒ"""
        # ä½¿ç”¨ beta åˆ†å¸ƒè®©æ—¶é—´æ›´ä¸è§„åˆ™ï¼ˆæ›´æ¥è¿‘äººç±»è¡Œä¸ºï¼‰
        if random.random() < 0.2:  # 20% æ¦‚ç‡å¿«é€Ÿååº”
            delay = random.uniform(min_seconds * 0.5, min_seconds)
        elif random.random() < 0.7:  # 50% æ¦‚ç‡æ­£å¸¸é€Ÿåº¦
            delay = random.uniform(min_seconds, (min_seconds + max_seconds) / 2)
        else:  # 30% æ¦‚ç‡æ…¢é€Ÿï¼ˆæ€è€ƒä¸­ï¼‰
            delay = random.uniform((min_seconds + max_seconds) / 2, max_seconds * 1.2)
        time.sleep(delay)

    def _random_mouse_movement(self, page: Page):
        """æ¨¡æ‹Ÿéšæœºé¼ æ ‡ç§»åŠ¨ - å®Œå…¨ä¸è§„åˆ™çš„æ—¶é—´é—´éš”"""
        num_moves = random.choice([1, 1, 2, 2, 3])  # æ›´å€¾å‘äºå°‘é‡ç§»åŠ¨
        for i in range(num_moves):
            x = random.randint(100, 1200)
            y = random.randint(100, 800)
            page.mouse.move(x, y)
            # æ¯æ¬¡ç§»åŠ¨çš„é—´éš”éƒ½ä¸åŒ
            if i < num_moves - 1:
                delays = [0.05, 0.08, 0.12, 0.15, 0.18, 0.25, 0.3, 0.35, 0.4, 0.5]
                time.sleep(random.choice(delays))

    def _human_scroll(self, page: Page):
        """äººç±»å¼æ»šåŠ¨ - å®Œå…¨ä¸è§„åˆ™çš„æ—¶é—´é—´éš”"""
        # éšæœºæ»šåŠ¨è·ç¦»
        scroll_choices = [
            (0.3, (100, 300)),    # 30% å°æ»šåŠ¨
            (0.5, (300, 600)),    # 50% ä¸­ç­‰æ»šåŠ¨
            (0.2, (600, 1000))    # 20% å¤§æ»šåŠ¨
        ]
        rand = random.random()
        cumulative = 0
        for prob, (min_s, max_s) in scroll_choices:
            cumulative += prob
            if rand < cumulative:
                scroll = random.randint(min_s, max_s)
                break

        # åˆ†æ­¥æ»šåŠ¨ï¼ˆäººç±»ä¸ä¼šä¸€æ¬¡æ»šåŠ¨ï¼‰- æ¯æ­¥é—´éš”ä¸åŒ
        steps = random.choice([2, 2, 3, 3, 4, 5])  # æ›´å€¾å‘äº2-3æ­¥
        scroll_per_step = scroll // steps

        for i in range(steps):
            # æ¯æ­¥æ»šåŠ¨è·ç¦»ä¹Ÿç•¥æœ‰å˜åŒ–
            variation = random.randint(-20, 20)
            page.evaluate(f"window.scrollBy({{top: {scroll_per_step + variation}, behavior: 'smooth'}})")
            # æ¯æ­¥ä¹‹é—´çš„æ—¶é—´å®Œå…¨ä¸åŒ
            step_delays = [0.03, 0.05, 0.08, 0.1, 0.12, 0.15, 0.18, 0.2, 0.25]
            time.sleep(random.choice(step_delays))

        # åœé¡¿"é˜…è¯»"å†…å®¹ - å®Œå…¨éšæœº
        reading_pauses = [0.5, 0.8, 1.0, 1.2, 1.5, 1.8, 2.0, 2.5, 3.0, 3.5]
        time.sleep(random.choice(reading_pauses))

        # æœ‰æ—¶å‘ä¸Šæ»šä¸€ç‚¹ï¼ˆåƒé‡æ–°é˜…è¯»ï¼‰
        if random.random() < 0.15:
            scroll_back = random.randint(-200, -50)
            page.evaluate(f"window.scrollBy({{top: {scroll_back}, behavior: 'smooth'}})")
            back_delays = [0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 1.0]
            time.sleep(random.choice(back_delays))

    def _random_pause(self):
        """å¶å°”åœé¡¿ï¼Œæ¨¡æ‹Ÿäººç±»åˆ†å¿ƒ"""
        if random.random() < 0.1:  # 10%æ¦‚ç‡
            pause_type = random.choice(['short', 'medium'])
            if pause_type == 'short':
                time.sleep(random.uniform(2, 5))
                logger.info("      â¸ï¸  Quick pause...")
            else:
                time.sleep(random.uniform(5, 10))
                logger.info("      â¸ï¸  Short break...")

    def _start_browser(self):
        """å¯åŠ¨Playwrightæµè§ˆå™¨"""
        if self.browser:
            return  # å·²ç»å¯åŠ¨

        logger.info("ğŸš€ Starting browser for LinkedIn...")

        self.playwright = sync_playwright().start()

        # å°è¯•ä½¿ç”¨Firefoxï¼ˆæ›´éš¾è¢«æ£€æµ‹ï¼‰
        try:
            logger.info("ğŸ¦Š Trying Firefox browser for better stealth...")
            self.browser = self.playwright.firefox.launch(
                headless=False,  # å¯è§æ¨¡å¼
                firefox_user_prefs={
                    "dom.webdriver.enabled": False,
                    "useAutomationExtension": False,
                    "general.platform.override": "MacIntel",
                    "general.useragent.override": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/115.0"
                }
            )
        except Exception as e:
            logger.warning(f"   Firefox not available, falling back to Chromium: {e}")
            # Fallback to Chromium with enhanced anti-detection
            self.browser = self.playwright.chromium.launch(
                headless=False,
                args=[
                    '--disable-blink-features=AutomationControlled',
                    '--disable-automation',
                    '--disable-web-security',
                    '--disable-features=IsolateOrigins,site-per-process',
                    '--no-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-gpu'
                ]
            )

        # åˆ›å»ºcontext - æ ¹æ®è®¤è¯æ–¹å¼é€‰æ‹©
        if self.use_storage_state and self.storage_state_file:
            # ä½¿ç”¨storage_stateï¼ˆæ¨èï¼Œç±»ä¼¼Twitterï¼‰
            logger.info(f"ğŸ” Loading authentication from {self.storage_state_file}...")
            context = self.browser.new_context(
                storage_state=self.storage_state_file,
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                locale='zh-CN',
                timezone_id='Asia/Shanghai',
                extra_http_headers={
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'DNT': '1',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1'
                }
            )
        else:
            # ä½¿ç”¨cookiesï¼ˆæ—§æ–¹æ³•ï¼‰
            context = self.browser.new_context(
                user_agent=self.headers.get('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'),
                viewport={'width': 1920, 'height': 1080},
                locale='zh-CN',
                timezone_id='Asia/Shanghai',
                extra_http_headers={
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'DNT': '1',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1'
                }
            )

            # è®¾ç½®cookies
            if self.cookies:
                context.add_cookies([
                    {
                        'name': 'li_at',
                        'value': self.cookies.get('li_at', ''),
                        'domain': '.linkedin.com',
                        'path': '/'
                    },
                    {
                        'name': 'JSESSIONID',
                        'value': self.cookies.get('JSESSIONID', ''),
                        'domain': '.linkedin.com',
                        'path': '/'
                    },
                    {
                        'name': 'liap',
                        'value': self.cookies.get('liap', 'true'),
                        'domain': '.linkedin.com',
                        'path': '/'
                    }
                ])

        self.page = context.new_page()

        # Inject anti-detection script (same as Twitter)
        self.page.add_init_script("""
            // Remove webdriver property
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });

            // Override plugins and languages
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5]
            });

            Object.defineProperty(navigator, 'languages', {
                get: () => ['zh-CN', 'zh', 'en']
            });

            // Override chrome property
            window.chrome = {
                runtime: {}
            };

            // Override permissions
            const originalQuery = window.navigator.permissions.query;
            window.navigator.permissions.query = (parameters) => (
                parameters.name === 'notifications' ?
                    Promise.resolve({ state: Notification.permission }) :
                    originalQuery(parameters)
            );
        """)

        logger.info("âœ… Browser started with authentication")

    def _close_browser(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.browser:
            self.browser.close()
            self.playwright.stop()
            self.browser = None
            self.playwright = None
            logger.info("ğŸ”’ Browser closed")

    def search_users(self, keywords: List[str], limit: int = 100) -> List[Dict]:
        """
        æœç´¢LinkedInç”¨æˆ·

        Args:
            keywords: æœç´¢å…³é”®è¯
            limit: ç»“æœæ•°é‡

        Returns:
            ç”¨æˆ·åˆ—è¡¨
        """
        self._start_browser()

        # æ„å»ºæœç´¢URL
        query = ' '.join(keywords)
        search_url = f"https://www.linkedin.com/search/results/people/?keywords={query.replace(' ', '%20')}"

        logger.info(f"ğŸ” Searching LinkedIn: {query}")

        try:
            # é¦–å…ˆè®¿é—®LinkedInä¸»é¡µï¼Œç¡®è®¤ç™»å½•çŠ¶æ€
            logger.info("   Navigating to LinkedIn homepage...")
            self.page.goto("https://www.linkedin.com/feed/", timeout=60000, wait_until='domcontentloaded')

            # äººç±»è¡Œä¸ºï¼šåˆ°è¾¾é¡µé¢åçš„é¼ æ ‡ç§»åŠ¨
            self._random_mouse_movement(self.page)
            self._human_like_delay(2, 4)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°ç™»å½•
            if "login" in self.page.url or "authwall" in self.page.url:
                logger.error("âŒ LinkedIn cookies expired - please run linkedin_login_and_save_auth.py")
                return []

            logger.info("   âœ… Successfully logged in")

            # ä½¿ç”¨æœç´¢æ¡†æœç´¢ï¼ˆæ¨¡æ‹ŸçœŸäººï¼‰
            logger.info("   ğŸ” Using search box (human-like)...")

            try:
                # æ‰¾åˆ°æœç´¢æ¡†
                search_box = self.page.query_selector('input[placeholder*="Search"]')
                if not search_box:
                    search_box = self.page.query_selector('.search-global-typeahead__input')

                if search_box:
                    # äººç±»è¡Œä¸ºï¼šç§»åŠ¨é¼ æ ‡åˆ°æœç´¢æ¡†é™„è¿‘
                    self._random_mouse_movement(self.page)
                    self._human_like_delay(0.5, 1.5)

                    # ç‚¹å‡»æœç´¢æ¡†
                    search_box.click()
                    self._human_like_delay(0.8, 1.8)

                    # æ¨¡æ‹Ÿé€å­—è¾“å…¥ - æ¯ä¸ªå­—ç¬¦çš„å»¶è¿Ÿéƒ½ä¸åŒï¼
                    # å®šä¹‰å¤šç§å¯èƒ½çš„å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
                    typing_delays = [
                        30, 45, 60, 75, 80, 90, 100, 110, 120, 135,
                        150, 165, 180, 200, 220, 250, 280, 300, 350
                    ]

                    for i, char in enumerate(query):
                        # æ¯ä¸ªå­—ç¬¦é€‰æ‹©ä¸åŒçš„å»¶è¿Ÿ
                        delay = random.choice(typing_delays)

                        # å¶å°”æ‰“å­—æ›´æ…¢ï¼ˆæ€è€ƒ/çŠ¹è±«ï¼‰
                        if random.random() < 0.15:  # 15%æ¦‚ç‡
                            delay = random.randint(300, 600)

                        # ç©ºæ ¼å‰åé€šå¸¸ç¨æ…¢
                        if char == ' ' or (i > 0 and query[i-1] == ' '):
                            delay = random.randint(150, 350)

                        search_box.type(char, delay=delay)

                    self._human_like_delay(0.5, 1.2)
                    search_box.press('Enter')
                    self._human_like_delay(2, 3)

                    # ç‚¹å‡»"People"æ ‡ç­¾
                    logger.info("   Clicking on People tab...")
                    people_button = self.page.query_selector('button:has-text("People")')
                    if not people_button:
                        people_button = self.page.query_selector('[aria-label="People"]')

                    if people_button:
                        # äººç±»è¡Œä¸ºï¼šç§»åŠ¨é¼ æ ‡åå†ç‚¹å‡»
                        self._random_mouse_movement(self.page)
                        self._human_like_delay(0.5, 1)
                        people_button.click()
                        self._human_like_delay(2, 4)
                    else:
                        logger.warning("   Could not find People tab, continuing anyway...")
                else:
                    logger.warning("   Could not find search box, trying direct URL...")
                    # å¦‚æœæ‰¾ä¸åˆ°æœç´¢æ¡†ï¼Œå°è¯•ç›´æ¥URL
                    self.page.goto(search_url, timeout=60000, wait_until='domcontentloaded')
                    self._human_like_delay(3, 5)

            except Exception as e:
                logger.warning(f"   Search box method failed: {e}, trying direct URL...")
                self.page.goto(search_url, timeout=60000, wait_until='domcontentloaded')
                self._human_like_delay(3, 5)

            # ç­‰å¾…æœç´¢ç»“æœåŠ è½½
            logger.info("   â³ Waiting for search results...")
            self._random_mouse_movement(self.page)
            self._human_like_delay(2, 4)

            # æ£€æŸ¥æ˜¯å¦å‡ºç°é”™è¯¯é¡µé¢ (LinkedIn sometimes shows error page)
            max_retries = 3
            for retry in range(max_retries):
                page_text = self.page.inner_text('body')
                if "This one's our fault" in page_text or "We're looking into it" in page_text:
                    logger.warning(f"   âš ï¸  LinkedIn error page detected (attempt {retry + 1}/{max_retries})")

                    # å°è¯•ç‚¹å‡»"Retry search"æŒ‰é’®
                    retry_button = self.page.query_selector('button:has-text("Retry search")')
                    if retry_button:
                        logger.info("   ğŸ”„ Clicking 'Retry search' button...")
                        self._random_mouse_movement(self.page)
                        self._human_like_delay(0.5, 1)
                        retry_button.click()
                        self._human_like_delay(3, 5)

                        # é‡æ–°ç­‰å¾…æœç´¢ç»“æœ
                        self._human_like_delay(2, 3)
                        continue
                    else:
                        # å¦‚æœæ²¡æœ‰é‡è¯•æŒ‰é’®ï¼Œå°è¯•åˆ·æ–°é¡µé¢
                        logger.info("   ğŸ”„ Refreshing page...")
                        self.page.reload()
                        self._human_like_delay(3, 5)
                        continue
                else:
                    # æ²¡æœ‰é”™è¯¯ï¼Œç»§ç»­
                    break

            # è°ƒè¯•ï¼šä¿å­˜æˆªå›¾å’Œé¡µé¢HTML
            try:
                self.page.screenshot(path='linkedin_search_debug.png')
                logger.info("   ğŸ“¸ Screenshot saved")

                # ä¿å­˜HTMLç”¨äºè°ƒè¯•DOMç»“æ„
                html_content = self.page.content()
                with open('linkedin_search_debug.html', 'w', encoding='utf-8') as f:
                    f.write(html_content)
                logger.info("   ğŸ“„ HTML saved for debugging")
            except Exception as e:
                logger.debug(f"   Could not save debug files: {e}")

        except Exception as e:
            logger.error(f"âŒ Error navigating to search page: {e}")
            logger.warning("âš ï¸  This might be due to:")
            logger.warning("   1. Expired cookies - update platforms_auth.json")
            logger.warning("   2. LinkedIn rate limiting - wait a few minutes")
            logger.warning("   3. Network issues - check your connection")
            return []

        users = []
        scroll_attempts = 0
        max_scrolls = limit // 10  # æ¯æ¬¡æ»šåŠ¨å¤§çº¦åŠ è½½10ä¸ªç»“æœ

        while len(users) < limit and scroll_attempts < max_scrolls:
            # äººç±»è¡Œä¸ºï¼šå¶å°”åˆ†å¿ƒåœé¡¿
            self._random_pause()

            # å°è¯•å¤šä¸ªé€‰æ‹©å™¨ï¼ˆLinkedInç»å¸¸æ”¹å˜DOMç»“æ„ï¼‰
            # æ ¹æ®æœ€æ–°çš„LinkedInç•Œé¢æ›´æ–°é€‰æ‹©å™¨
            user_cards = self.page.query_selector_all('li.reusable-search__result-container')

            if not user_cards:
                # å°è¯•æ›´é€šç”¨çš„é€‰æ‹©å™¨
                user_cards = self.page.query_selector_all('.search-results-container li')

            if not user_cards:
                # å°è¯•å¦ä¸€ä¸ªå¸¸è§é€‰æ‹©å™¨
                user_cards = self.page.query_selector_all('[data-chameleon-result-urn]')

            if not user_cards:
                # æœ€é€šç”¨çš„é€‰æ‹©å™¨
                user_cards = self.page.query_selector_all('ul.reusable-search__entity-result-list > li')

            logger.info(f"   Found {len(user_cards)} user cards on page")

            # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œæ‰“å°é¡µé¢HTMLå¸®åŠ©è°ƒè¯•
            if not user_cards and scroll_attempts == 0:
                logger.warning("   âš ï¸  Could not find user cards, checking page structure...")
                # å°è¯•æŸ¥æ‰¾People section
                people_section = self.page.query_selector('.search-results-container')
                if people_section:
                    logger.info("   âœ“ Found search results container")
                else:
                    logger.warning("   âœ— No search results container found")

            for card in user_cards[len(users):]:  # åªå¤„ç†æ–°çš„å¡ç‰‡
                try:
                    # äººç±»è¡Œä¸ºï¼šå¤„ç†æ¯ä¸ªå¡ç‰‡ä¹‹é—´æœ‰å°å»¶è¿Ÿ - å®Œå…¨éšæœº
                    if random.random() < 0.3:  # 30%æ¦‚ç‡ç§»åŠ¨é¼ æ ‡
                        self._random_mouse_movement(self.page)

                    # æå–ç”¨æˆ·ä¿¡æ¯ - å°è¯•å¤šä¸ªé€‰æ‹©å™¨
                    name_elem = card.query_selector('.entity-result__title-text a')
                    if not name_elem:
                        name_elem = card.query_selector('a.app-aware-link')
                    if not name_elem:
                        name_elem = card.query_selector('.entity-result__title-line a')

                    headline_elem = card.query_selector('.entity-result__primary-subtitle')
                    if not headline_elem:
                        headline_elem = card.query_selector('.entity-result__summary')

                    location_elem = card.query_selector('.entity-result__secondary-subtitle')
                    if not location_elem:
                        location_elem = card.query_selector('.entity-result__location')

                    if name_elem:
                        profile_url = name_elem.get_attribute('href')
                        # æ¸…ç†profile URLï¼ˆç§»é™¤æŸ¥è¯¢å‚æ•°ï¼‰
                        if profile_url and '?' in profile_url:
                            profile_url = profile_url.split('?')[0]

                        user = {
                            'name': name_elem.inner_text().strip(),
                            'profile_url': profile_url or '',
                            'headline': headline_elem.inner_text().strip() if headline_elem else '',
                            'location': location_elem.inner_text().strip() if location_elem else '',
                            'platform': 'linkedin'
                        }
                        users.append(user)
                        logger.debug(f"   Added user: {user['name']}")

                        # äººç±»è¡Œä¸ºï¼šæå–ä¿¡æ¯åç¨å¾®åœé¡¿ - æ¯æ¬¡éƒ½ä¸åŒ
                        card_delays = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.2, 1.5]
                        time.sleep(random.choice(card_delays))

                        if len(users) >= limit:
                            break

                except Exception as e:
                    logger.debug(f"Error extracting user card: {e}")
                    continue

            # æ»šåŠ¨åŠ è½½æ›´å¤šï¼ˆä½¿ç”¨äººç±»å¼æ»šåŠ¨ï¼‰
            if len(users) < limit:
                logger.info(f"   ğŸ“œ Scrolling for more results... (attempt {scroll_attempts + 1})")
                self._human_scroll(self.page)  # ä½¿ç”¨äººç±»å¼æ»šåŠ¨
                scroll_attempts += 1

        logger.info(f"âœ… Found {len(users)} users on LinkedIn")
        return users[:limit]

    def get_user_profile(self, user_id: str) -> Dict:
        """
        è·å–LinkedInç”¨æˆ·è¯¦ç»†èµ„æ–™

        Args:
            user_id: ç”¨æˆ·profile URL

        Returns:
            ç”¨æˆ·è¯¦ç»†èµ„æ–™
        """
        if not self.browser:
            self._start_browser()

        # user_id å®é™…ä¸Šæ˜¯profile URL
        profile_url = user_id if user_id.startswith('http') else f"https://www.linkedin.com/in/{user_id}"

        logger.debug(f"ğŸ“– Fetching profile: {profile_url}")

        try:
            self.page.goto(profile_url, timeout=60000, wait_until='domcontentloaded')

            # äººç±»è¡Œä¸ºï¼šåˆ°è¾¾é¡µé¢åçš„é¼ æ ‡ç§»åŠ¨å’Œå»¶è¿Ÿ
            self._random_mouse_movement(self.page)
            self._human_like_delay(1.5, 3)

            # äººç±»è¡Œä¸ºï¼šæ»šåŠ¨æŸ¥çœ‹é¡µé¢ï¼ˆåƒé˜…è¯»èµ„æ–™ï¼‰
            if random.random() < 0.7:  # 70%æ¦‚ç‡æ»šåŠ¨
                self._human_scroll(self.page)

        except Exception as e:
            logger.warning(f"âš ï¸  Error loading profile {profile_url}: {e}")
            return {
                'profile_url': profile_url,
                'platform': 'linkedin'
            }

        # æå–è¯¦ç»†ä¿¡æ¯
        profile = {
            'profile_url': profile_url,
            'platform': 'linkedin'
        }

        try:
            # å§“å
            name_elem = self.page.query_selector('h1.text-heading-xlarge')
            if name_elem:
                profile['name'] = name_elem.inner_text().strip()

            # æ ‡é¢˜/èŒä½
            headline_elem = self.page.query_selector('.text-body-medium')
            if headline_elem:
                profile['headline'] = headline_elem.inner_text().strip()
                profile['job_title'] = headline_elem.inner_text().strip()

            # åœ°ç‚¹
            location_elem = self.page.query_selector('.text-body-small.inline.t-black--light.break-words')
            if location_elem:
                profile['location'] = location_elem.inner_text().strip()

            # å…³äº/ç®€ä»‹
            about_elem = self.page.query_selector('#about ~ .pvs-list__outer-container')
            if about_elem:
                profile['bio'] = about_elem.inner_text().strip()[:500]

            # å½“å‰å…¬å¸ï¼ˆä»ç»éªŒéƒ¨åˆ†æå–ï¼‰
            experience_elem = self.page.query_selector('#experience ~ .pvs-list__outer-container li')
            if experience_elem:
                company_elem = experience_elem.query_selector('.t-bold span')
                if company_elem:
                    profile['company'] = company_elem.inner_text().strip()

        except Exception as e:
            logger.warning(f"âš ï¸  Error extracting profile details: {e}")

        return profile

    def extract_email(self, user_profile: Dict) -> Optional[str]:
        """
        ä»LinkedInèµ„æ–™æå–é‚®ç®±

        LinkedIné€šå¸¸ä¸å…¬å¼€é‚®ç®±ï¼Œéœ€è¦ï¼š
        1. ç‚¹å‡»"Contact Info"
        2. æˆ–ä»å…¬å¸åŸŸå + Hunter.ioæ¨æ–­

        Args:
            user_profile: ç”¨æˆ·èµ„æ–™

        Returns:
            é‚®ç®±åœ°å€æˆ–None
        """
        # LinkedIné€šå¸¸ä¸å…¬å¼€é‚®ç®±
        # æˆ‘ä»¬è¿”å›Noneï¼Œè®©Hunter.ioä»å…¬å¸åŸŸåæ¨æ–­
        return None

    def get_company_employees(self, company_name: str, limit: int = 50) -> List[Dict]:
        """
        è·å–å…¬å¸å‘˜å·¥åˆ—è¡¨

        Args:
            company_name: å…¬å¸åç§°
            limit: æ•°é‡é™åˆ¶

        Returns:
            å‘˜å·¥åˆ—è¡¨
        """
        keywords = [company_name, "recruiter"]  # æœç´¢è¯¥å…¬å¸çš„æ‹›è˜äººå‘˜
        return self.search_users(keywords, limit)

    def __del__(self):
        """ææ„å‡½æ•° - æ¸…ç†èµ„æº"""
        self._close_browser()


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    scraper = LinkedInScraper()

    # æµ‹è¯•æœç´¢
    test_keywords = ["recruiter", "hiring manager", "tech"]
    users = scraper.search_users(test_keywords, limit=5)

    print(f"\nâœ… Found {len(users)} users:")
    for user in users:
        print(f"  - {user['name']} | {user.get('headline', 'N/A')}")

    # æµ‹è¯•è·å–è¯¦æƒ…
    if users:
        profile = scraper.get_user_profile(users[0]['profile_url'])
        print(f"\nğŸ“– Profile details:")
        print(f"  Name: {profile.get('name')}")
        print(f"  Title: {profile.get('job_title')}")
        print(f"  Company: {profile.get('company')}")
        print(f"  Location: {profile.get('location')}")

    scraper._close_browser()
